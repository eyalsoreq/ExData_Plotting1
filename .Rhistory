log10 (training$Superplasticizer)
.clc()
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
vars <- names(training)
vars
is.element("IL",vars)
df[,grep("^[IL]", vars, value=TRUE)]
df[,grep("^[IL]", names(training), value=TRUE)]
grep("^[IL]", names(training), value=TRUE)
grep("^[IL_]", names(training), value=TRUE)
pmatch("IL", names(training), value=TRUE)
pmatch("IL", names(training))
subset(training, grepl("^IL", training), drop = TRUE)
subset(training, grepl("IL", training), drop = TRUE)
grepl("^IL",vars)
subTraining <- training(grepl("^IL",vars))
subTraining <- training(grepl("^IL",vars))
training
subTraining <- training(:,grepl("^IL",vars))
subTraining <- training[,grepl("^IL",vars)]
View(subTraining)
View(subTraining)
log10(subTraining)
prePRoc <- preProcess(subTraining,method="pca",pcaComp=2),
subTraining
preProcess(subTraining,method="pca",pcaComp=2)
prePRoc <- preProcess(subTraining,method="pca",pcaComp=2)
col=diagnosis[inTrain]
plot(prePRoc[,1], prePRoc[,2], col=diagnosis[inTrain])
prePRoc
preProc <- preProcess(subTraining,method="pca",pcaComp=2)
dataPC <- predict(preProc, subTraining)
plot(dataPC[,1], dataPC[,2], col=diagnosis[inTrain])
subTesting <- testing[,grepl("^IL",vars)]
preProc <- preProcess(subTraining,method="pca")
testPC <- predict(preProc,subTesting )
confusionMatrix(testing, predict(modelFit, testPC))
confusionMatrix(diagnosis[inTrain], predict(modelFit, testPC))
confusionMatrix(diagnosis[-inTrain], predict(modelFit, testPC))
diagnosis[-inTrain]
predict(modelFit, testPC)
modelFit <- train(diagnosis[inTrain] ~., method="glm", preProcess="pca", data=subTraining)
install.packages("e1071")
modelFit <- train(diagnosis[inTrain] ~., method="glm", preProcess="pca", data=subTraining)
confusionMatrix(diagnosis[-inTrain], predict(modelFit, testPC))
modelFit <- train(diagnosis[inTrain] , method="glm", preProcess="pca", data=subTraining)
modelFit <- train(diagnosis[inTrain] subTraining, method="glm", preProcess="pca", data=subTraining)
modelFit <- train(diagnosis[inTrain] ~., method="glm", preProcess="pca", data=subTraining)
testPC <- predict(preProc,subTesting )
confusionMatrix(diagnosis[-inTrain], predict(modelFit, testPC))
modelFit <- train(diagnosis[inTrain] ~., method="glm", preProcess="pca", data=subTesting)
View(subTesting)
View(subTesting)
modelFit <- train(diagnosis[-inTrain] ~., method="glm", preProcess="pca", data=subTesting)
confusionMatrix(diagnosis[-inTrain], predict(modelFit, testPC))
diagnosis[-inTrain]
predict(modelFit, testPC)
testPC
modelFit <- train(diagnosis[-inTrain] ~., method="glm", preProc)
i in vars
for (i in vars) { # recode all events so large is good
subTraining[,i] <- max(subTraining[,i])- subTraining[,i]
}
subTraining[,i]
View(subTraining)
View(subTraining)
subVars = names(subTraining)
for (i in subVars) { # recode all events so large is good
subTraining[,i] <- max(subTraining[,i])- subTraining[,i]
}
plot(subTraining)
plot(subTraining color=diagnosis[inTrain]) # plot scatter plot matrix of all elments
plot(subTraining, color=diagnosis[inTrain]) # plot scatter plot matrix of all elments
warnings()
qplot(subTraining, color=diagnosis[inTrain]) # plot scatter plot matrix of all elments
featurePlot(x=subTraining,y=diagnosis[inTrain], plot="pairs") # plot scatter plot matrix of all elments
x11()
featurePlot(x=subTraining,y=diagnosis[inTrain], plot="pairs") # plot scatter plot matrix of all elments
round(cor(subTraining), 2) # plot corelation matrix of all features
corMat <- round(cor(subTraining), 2) # plot corelation matrix of all features
diag(corMat)
diag(corMat)<-0
corMat
subTrainingPca <- prcomp(subTraining, scale = TRUE)
print(subTrainingPca)
summary(subTrainingPca)
.clc()
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(rattle)
library(devtools)
library(randomForest)
library(caret)
library(ggbiplot)
dat <- read.csv("/Users/eyalsoreq/Dropbox/MachineLearning/PRIME project/PrimeFeatures.csv")
set.seed(44432)
ix <- dat$condition=="approach easy" | dat$condition=="approach hard"
dat$motivation[ix] = "Approach"
dat$motivation[!ix]= "Avoidance"
ix <- dat$condition=="mixed easy" |dat$condition=="mixed hard" |dat$condition=="null"
dat$motivation[ix]= "Other"
dat = dat[!ix,]
dat<- na.omit(dat)
dat$motivation = as.factor(dat$motivation)
inTrain = createDataPartition(dat$motivation, p = 0.75)[[1]] # partition the data to training and testing
set.seed(33356)
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,14,16:19,51)]
summary(training$motivation)
summary(testing$motivation)
summary(training)
summary(training$outcome)
table(training$outcome)
library(car)
scatterplotMatrix(testing, diagonal=c("density", "boxplot"), groups=testing$motivation)
scatterplotMatrix(testing, diagonal=c("boxplot"), groups=testing$motivation)
scatterplotMatrix(testing, groups=testing$motivation)
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',preProcess=c("pca"),prox=TRUE,importance=T)
modFit.rf$importance
modFit.rf <-  randomForest(motivation ~ distance_end+distance_middle+distance_start+outcome+engagment+PSD_1,data=training,model='rf',preProcess=c("pca"),prox=TRUE,importance=T)
modFit.rf$importance
#table(training$condition, predict(modFit, training, type="response"))
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
modFit.rf <-  randomForest(motivation ~ distance_end+distance_middle+distance_start+outcome+engagment+PSD_1+RT,data=training,model='rf',preProcess=c("pca"),prox=TRUE,importance=T)
#table(training$condition, predict(modFit, training, type="response"))
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
scatterplotMatrix(modFit.rf, data=testing, groups=testing$motivation)
scatterplotMatrix(modFit.rf)
modFit.rf$localImportance
modFit.rf$forest
plot(modFit.rf$forest)
modFit.rf$call
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',preProcess=c("pca"+"scale"),prox=TRUE,importance=T)
modFit.rf$importance
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
modFit.rf <-  randomForest(motivation ~ distance_end+distance_middle+distance_start+outcome+engagment+PSD_1+RT,data=training,model='rf',preProcess=c("pca"+"scale"),prox=TRUE,importance=T)
library(rattle)
library(devtools)
library(randomForest)
library(caret)
library(ggbiplot)
library(car)
dat <- read.csv("/Users/eyalsoreq/Dropbox/MachineLearning/PRIME project/PrimeFeatures.csv")
set.seed(44432)
ix <- dat$condition=="approach easy" | dat$condition=="approach hard"
dat$motivation[ix] = "Approach"
dat$motivation[!ix]= "Avoidance"
ix <- dat$condition=="mixed easy" |dat$condition=="mixed hard" |dat$condition=="null"
dat$motivation[ix]= "Other"
dat = dat[!ix,]
dat<- na.omit(dat)
dat$motivation = as.factor(dat$motivation)
inTrain = createDataPartition(dat$motivation, p = 0.75)[[1]] # partition the data to training and testing
set.seed(33356)
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,14,16:19,51)]
table(training$outcome)
summary(testing$motivation)
ix = c(1:4,6:(length(training)-1))
R<-cor(training[,ix])
library(corrplot)
corrplot(R, method = "circle")
modFit.glm <-  train(motivation ~ .,data=training,model='glm',preProcess=c("pca"+"scale"))
modFit.glm <-  train(motivation ~ .,data=training,model='glm',preProcess=c("pca"))
modFit.glm <-  glm(motivation ~ .,data=training,family = Gamma)
modFit.glm <-  glm(motivation ~ .,data=training)
library(aod)
install.packages("aod")
modFit.glm <-  glm(motivation ~ .,data=training,family = "binomial")
summary(modFit.glm)
confint(modFit.glm)
confint.default(modFit.glm)
xtab <- table(testing$motivation, predict(modFit.glm, testing, type="response"))
confusionMatrix(xtab)
xtab
predict(modFit.rf, testing, type="response")
predict(modFit.glm, testing, type="response")
predict(modFit.glm, testing, type="response")>0.5
xtab <- table(testing$motivation, predict(modFit.glm, testing, type="response")>0.5)
confusionMatrix(xtab)
table(xtab)
testing$motivation
predict(modFit.glm, testing, type="response")
tt <- predict(modFit.glm, testing, type="response")
tt[tt>0.5] <- "Approach"
tt[tt<=0.5] <- "Avoidence"
xtab <- table(testing$motivation,tt )
xtab
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',preProcess=c("pca"+"scale"),prox=TRUE,importance=T)
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
modFit.rf$call
modFit.rf$type
modFit.rf$predicted
modFit.rf$err.rate
modFit.rf$confusion
modFit.rf$votes
modFit.rf$ntree
modFit.rf$inbag
modFit.rf$forest
modFit.rf$classes
modFit.rf$proximity
modFit.rf$y
modFit.rf$mtry
getTree(modFit.rf, 1, labelVar=TRUE)
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
summary(rpartFit)
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="response"))
predict(modFit.rpart, testing, type="raw")
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
modFit.rpart$bestTune
modFit.rpart$finalModel
modFit.rpart <- train(motivation ~ outcome+engagment+PSD_1+RT,data=training, method="rpart")
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
dat$distance_end = abs(dat$distance_end)
set.seed(33356)
inTrain = createDataPartition(dat$motivation, p = 0.75)[[1]] # partition the data to training and testing
set.seed(33356)
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,14,16:19,51)]
table(training$outcome)
summary(testing$motivation)
ix = c(1:4,6:(length(training)-1))
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
dat$distance_end = abs(dat$distance_end)
dat$distance_middle = abs(dat$distance_middle)
dat$motivation = as.factor(dat$motivation)
set.seed(33356)
inTrain = createDataPartition(dat$motivation, p = 0.75)[[1]] # partition the data to training and testing
set.seed(33356)
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,14,16:19,51)]
table(training$outcome)
summary(testing$motivation)
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
library(rattle)
library(devtools)
library(randomForest)
library(caret)
library(ggbiplot)
library(car)
library(aod)
dat <- read.csv("/Users/eyalsoreq/Dropbox/MachineLearning/PRIME project/normPrimeFeatures.csv")
set.seed(44432)
ix <- dat$condition=="approach easy" | dat$condition=="approach hard"
dat$motivation[ix] = "Approach"
dat$motivation[!ix]= "Avoidance"
ix <- dat$condition=="mixed easy" |dat$condition=="mixed hard" |dat$condition=="null"
dat$motivation[ix]= "Other"
dat = dat[!ix,]
dat<- na.omit(dat)
dat$motivation = as.factor(dat$motivation)
set.seed(33356)
inTrain = createDataPartition(dat$motivation, p = 0.75)[[1]] # partition the data to training and testing
set.seed(33356)
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,14,16:19,51)]
table(training$outcome)
summary(testing$motivation)
ix = c(1:4,6:(length(training)-1))
R<-cor(training[,ix])
library(corrplot)
corrplot(R, method = "circle")
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
View(testing)
View(dat)
dat <- read.csv("/Users/eyalsoreq/Dropbox/MachineLearning/PRIME project/normPrimeFeatures.csv")
set.seed(44432)
ix <- dat$condition=="approach easy" | dat$condition=="approach hard"
dat$motivation[ix] = "Approach"
dat$motivation[!ix]= "Avoidance"
ix <- dat$condition=="mixed easy" |dat$condition=="mixed hard" |dat$condition=="null"
dat$motivation[ix]= "Other"
dat = dat[!ix,]
dat<- na.omit(dat)
dat$motivation = as.factor(dat$motivation)
set.seed(33356)
inTrain = createDataPartition(dat$motivation, p = 0.75)[[1]] # partition the data to training and testing
set.seed(33356)
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,14,16:19,51)]
table(training$outcome)
summary(testing$motivation)
ix = c(1:4,6:(length(training)-1))
R<-cor(training[,ix])
library(corrplot)
corrplot(R, method = "circle")
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
View(testing)
View(testing)
View(dat)
training = dat[ inTrain,c(4:7,11:12,14,16:50,51)]
testing = dat[-inTrain,c(4:7,11:12,14,16:50,51)]
modFit.rpart <- train(motivation ~ .,data=training, method="rpart")
summary(modFit.rpart)
xtab <- table(testing$motivation, predict(modFit.rpart, testing, type="raw"))
confusionMatrix(xtab)
fancyRpartPlot(modFit.rpart$finalModel)
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',preProcess=c("pca"+"scale"),prox=TRUE,importance=T)
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
modFit.rf$importance
training = dat[ inTrain,c(5:7,11:12,14,16:19,51)]
View(training)
View(training)
View(dat)
View(dat)
training = dat[ inTrain,c(5:7,11:12,16:19,51)]
testing = dat[-inTrain,c(5:7,11:12,16:19,51)]
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',preProcess=c("pca"+"scale"),prox=TRUE,importance=T)
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
training = dat[ inTrain,c(5:7,11:12,16:18,51)]
testing = dat[-inTrain,c(5:7,11:12,16:18,51)]
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',preProcess=c("pca"+"scale"),prox=TRUE,importance=T)
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
training = dat[ inTrain,c(4:7,11:12,16:18,51)]
testing = dat[-inTrain,c(4:7,11:12,16:18,51)]
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',prox=TRUE,importance=T)
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
training = dat[ inTrain,c(4:7,11:12,16:18,51)]
testing = dat[-inTrain,c(4:7,11:12,16:18,51)]
training = dat[ inTrain,c(4:7,11:12,16:19,51)]
testing = dat[-inTrain,c(4:7,11:12,16:19,51)]
modFit.rf <-  randomForest(motivation ~ .,data=training,model='rf',prox=TRUE,importance=T)
xtab <- table(testing$motivation, predict(modFit.rf, testing, type="response"))
confusionMatrix(xtab)
scatterplotMatrix(testing, groups=testing$motivation)
modFit.pcaNNet  <- train(motivation ~ .,data=training, method="pcaNNet")
xtab <- table(testing$motivation, predict(modFit.pcaNNe, testing, type="raw"))
confusionMatrix(xtab)
modFit.pcaNNet$finalModel
modFit.pcaNNet$modelType
modFit.pcaNNet$pred
modFit.pcaNNet$bestTune
modFit.kernelpls <- train(motivation ~ .,data=training, method="kernelpls")
modFit.kernelpls <- train(motivation ~ .,data=training, method="kernelpls")
xtab <- table(testing$motivation, predict(modFit.kernelpls , testing, type="raw"))
confusionMatrix(xtab)
modFit.kernelpls$coefnames
modFit.treebag<- train(motivation ~ .,data=training, method="treebag")
xtab <- table(testing$motivation, predict(modFit.treebag , testing, type="raw"))
confusionMatrix(xtab)
modFit.RRF<- train(motivation ~ .,data=training, method="RRF")
xtab <- table(testing$motivation, predict(modFit.RRF , testing, type="raw"))
confusionMatrix(xtab)
quartz()
plot(dat$Time, dat$Sub_metering_1,
type = "l",
col = "black",
main = "",
ylab = "Energy sub metering",
xlab = "",
xaxt = "n")
setwd("/Users/eyalsoreq/ExData_Plotting1")
dat <- read.table(pipe('grep "^[1-2]/2/2007" "household_power_consumption.txt"'),header=F, sep=';')
colnames(dat) <-names(read.table('household_power_consumption.txt', header=TRUE,sep=";",nrows=1))
dat$Date <- as.Date(dat$Date,  "%d/%m/%Y")
dat$Time <- strptime(paste(dat$Date, ' ', dat$Time ), "%Y-%m-%d %H:%M:%S")
# missing values are coded as ?
### plot 01 hist of
png(file = "plot01.png",width = 480, height = 480, units = "px")
with(dat, hist(dat$Global_active_power,
main = "Global active power",  ## Add a title
xlab = "Global active power (kilowatts)",  ## Add xlabel
col = "red"))  ## color bars red
hist(dat$Global_active_power,
main = "Global active power",  ## Add a title
xlab = "Global active power (kilowatts)",  ## Add xlabel
col = "red")
with(dat, hist(dat$Global_active_power,
main = "Global active power",  ## Add a title
xlab = "Global active power (kilowatts)",  ## Add xlabel
col = "red"))
axis.POSIXct(side = 1, dat$Time, format = "%A")
dev.off()
type = "l",
main = "Global active power",  ## Add a title
ylab = "Global active power (kilowatts)",
xlab = "",
xaxt = "n"))
axis.POSIXct(side = 1, dat$Time, format = "%A")
with(dat, plot(dat$Time, dat$Global_active_power,
type = "l",
main = "Global active power",  ## Add a title
ylab = "Global active power (kilowatts)",
xlab = "",
xaxt = "n"))
axis.POSIXct(side = 1, dat$Time, format = "%A")
dev.off()
png(file = "plot03.png",width = 480, height = 480, units = "px")
png(file = "plot03.png",width = 480, height = 480, units = "px")
with(dat, plot(dat$Time, dat$Sub_metering_1,
type = "l",
col = "black",
main = "",
ylab = "Energy sub metering",
xlab = "",
xaxt = "n"))
ylim <- par("yaxp")[1:2]
png(file = "plot02.png",width = 480, height = 480, units = "px")
with(dat, plot(dat$Time, dat$Global_active_power,
type = "l",
main = "Global active power",  ## Add a title
ylab = "Global active power (kilowatts)",
xlab = "",
xaxt = "n"))
axis.POSIXct(side = 1, dat$Time, format = "%A")
dev.off()
ylim <- par("yaxp")[1:2]
axis.POSIXct(side = 1, dat$Time, format = "%A")
axis.POSIXct(side = 1, dat$Time, format = "%A")
par(new=T); plot(dat$Time, dat$Sub_metering_2,type = "l",col = "red",ylim=ylim )
par(new=T); plot(dat$Time, dat$Sub_metering_3,type = "l",col = "blue",ylim=ylim )
png(file = "plot03.png",width = 480, height = 480, units = "px")
with(dat, plot(dat$Time, dat$Sub_metering_1,
type = "l",
col = "black",
main = "",
ylab = "Energy sub metering",
xlab = "",
xaxt = "n"))
ylim <- par("yaxp")[1:2]
axis.POSIXct(side = 1, dat$Time, format = "%A")
par(new=T); plot(dat$Time, dat$Sub_metering_2,type = "l",col = "red",ylim=ylim )
par(new=T); plot(dat$Time, dat$Sub_metering_3,type = "l",col = "blue",ylim=ylim )
par(new=F)
png(file = "plot03.png",width = 480, height = 480, units = "px")
with(dat, plot(dat$Time, dat$Sub_metering_1,
type = "l",
col = "black",
main = "",
ylab = "Energy sub metering",
xlab = "",
xaxt = "n"))
ylim <- par("yaxp")[1:2]
axis.POSIXct(side = 1, dat$Time, format = "%A")
par(new=T); plot(dat$Time, dat$Sub_metering_2,type = "l",col = "red",ylim=ylim )
par(new=T); plot(dat$Time, dat$Sub_metering_3,type = "l",col = "blue",ylim=ylim )
par(new=F)
dev.off()
plot(cars)
quarters()
png(file = "plot03.png",width = 480, height = 480, units = "px")
with(dat, plot(dat$Time, dat$Sub_metering_1,
type = "l",
col = "black",
main = "",
ylab = "Energy sub metering",
xlab = "",
xaxt = "n"))
ylim <- par("yaxp")[1:2]
axis.POSIXct(side = 1, dat$Time, format = "%A")
par(new=T); plot(dat$Time, dat$Sub_metering_2,type = "l",col = "red",ylim=ylim )
par(new=T); plot(dat$Time, dat$Sub_metering_3,type = "l",col = "blue",ylim=ylim )
par(new=F)
quarters()
png(file = "plot03.png",width = 480, height = 480, units = "px")
with(dat, plot(dat$Time, dat$Sub_metering_1,
type = "l",
col = "black",
main = "",
ylab = "Energy sub metering",
xlab = "",
xaxt = "n"))
ylim <- par("yaxp")[1:2]
axis.POSIXct(side = 1, dat$Time, format = "%A")
par(new=T); plot(dat$Time, dat$Sub_metering_2,type = "l",col = "red",ylim=ylim )
par(new=T); plot(dat$Time, dat$Sub_metering_3,type = "l",col = "blue",ylim=ylim )
par(new=F)
